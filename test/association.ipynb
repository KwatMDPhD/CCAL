{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import ccal\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (16, 10)\n",
    "mpl.rcParams['figure.max_open_warning'] = 200\n",
    "\n",
    "HOME_DIR = os.environ['HOME']\n",
    "CCLE_DIR = os.path.join(HOME_DIR, 'data', 'ccle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_matrix = ccal.read_gct('data/nmf_k9_h.gct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variant_filepath = os.path.join(CCLE_DIR, 'ccle_variants.gct')\n",
    "variant_df = ccal.read_gct(variant_filepath)\n",
    "\n",
    "gene_dependency_filepath = os.path.join(CCLE_DIR, 'ccle_gene_dependencies.gct')\n",
    "gene_dependency_df = ccal.read_gct(gene_dependency_filepath)\n",
    "\n",
    "gene_expression_filepath = os.path.join(CCLE_DIR, 'ccle_gene_expressions.gct')\n",
    "gene_expression_df = ccal.read_gct(gene_expression_filepath)\n",
    "\n",
    "pathway_expression_filepath = os.path.join(CCLE_DIR, 'ccle_pathway_expressions.gct')\n",
    "pathway_expression_df = ccal.read_gct(pathway_expression_filepath)\n",
    "\n",
    "protein_expression_filepath = os.path.join(CCLE_DIR, 'ccle_protein_expressions.gct')\n",
    "protein_expression_df = ccal.read_gct(protein_expression_filepath)\n",
    "\n",
    "pathology_filepath = os.path.join(CCLE_DIR, 'ccle_pathologies.gct')\n",
    "pathology_df = ccal.read_gct(pathology_filepath)\n",
    "\n",
    "phenotype_filepath = os.path.join(CCLE_DIR, 'ccle_phenotypes.gct')\n",
    "phenotype_df = ccal.read_gct(phenotype_filepath)\n",
    "\n",
    "drug_dependency_filepath = os.path.join(CCLE_DIR, 'ccle_drug_sensitivities.gct')\n",
    "drug_dependency_df = ccal.read_gct(drug_dependency_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test make_association_panels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make target bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "component = 9\n",
    "target_bundle = [['H Matrix', h_matrix, 'continuous', False, 0, component, 'Component {}'.format(component)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make feature bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_bundles = {}\n",
    "\n",
    "n_features = 30\n",
    "feature_indices = list(range(n_features))\n",
    "\n",
    "feature_bundles['features=filepath'] = [['Variant', variant_filepath, 'binary', False, 0, feature_indices, []],\n",
    "                                        ['Gene Dependency', gene_dependency_filepath, 'continuous', True, 0, feature_indices, []],\n",
    "                                        ['Gene Expression', gene_expression_filepath, 'continuous', False, 0, feature_indices, []],\n",
    "                                        ['Pathway Expression', pathway_expression_filepath, 'continuous', False, 0, feature_indices, []],\n",
    "                                        ['Protein Expression', protein_expression_filepath, 'continuous', False, 0, feature_indices, []],\n",
    "                                        ['Pathology',  pathology_filepath, 'binary', False, 0, [], []],\n",
    "                                        ['Phenotype', phenotype_filepath, 'binary', False, 0, feature_indices, []],\n",
    "                                        ['Drug Sensitivity', drug_dependency_filepath, 'continuous', True, 0, feature_indices, []]]\n",
    "\n",
    "feature_bundles['features=df'] = [['Variant', variant_df, 'binary', False, 0, feature_indices, []],\n",
    "                                  ['Gene Dependency', gene_dependency_df, 'continuous', True, 0, feature_indices, []],\n",
    "                                  ['Gene Expression', gene_expression_df, 'continuous', False, 0, feature_indices, []],\n",
    "                                  ['Pathway Expression', pathway_expression_df, 'continuous', False, 0, feature_indices, []],\n",
    "                                  ['Protein Expression', protein_expression_df, 'continuous', False, 0, feature_indices, []],\n",
    "                                  ['Pathology',  pathology_df, 'binary', False, 0, [], []],\n",
    "                                  ['Phenotype', phenotype_df, 'binary', False, 0, feature_indices, []],\n",
    "                                  ['Drug Sensitivity', drug_dependency_df, 'continuous', True, 0, feature_indices, []]]\n",
    "\n",
    "feature_aliases = ['Feature {}'.format(f) for f in feature_indices]\n",
    "feature_bundles['feature_aliases'] = [['Variant', variant_df, 'binary', False, 0, feature_indices, feature_aliases],\n",
    "                                      ['Gene Dependency', gene_dependency_df, 'continuous', True, 0, feature_indices, feature_aliases],\n",
    "                                      ['Gene Expression', gene_expression_df, 'continuous', False, 0, feature_indices, feature_aliases],\n",
    "                                      ['Pathway Expression', pathway_expression_df, 'continuous', False, 0, feature_indices, feature_aliases],\n",
    "                                      ['Protein Expression', protein_expression_df, 'continuous', False, 0, feature_indices, feature_aliases],\n",
    "                                      ['Pathology',  pathology_df, 'binary', False, 0, [], feature_aliases],\n",
    "                                      ['Phenotype', phenotype_df, 'binary', False, 0, feature_indices, feature_aliases],\n",
    "                                      ['Drug Sensitivity', drug_dependency_df, 'continuous', True, 0, feature_indices, feature_aliases]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use indices as feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<150222> Loading targets bundle ...\n",
      "<150222> Reading H Matrix ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: continuous.\n",
      "<150222> \tIs ascending: False.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: 9.\n",
      "<150222> \tIndex alias: Component 9.\n",
      "<150222> \tRead 1 features & 750 samples.\n",
      "<150222> Loading feature bundle ...\n",
      "<150222> Reading Variant ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: binary.\n",
      "<150222> \tIs ascending: False.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 30 features & 1030 samples.\n",
      "<150222> Reading Gene Dependency ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: continuous.\n",
      "<150222> \tIs ascending: True.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 30 features & 503 samples.\n",
      "<150222> Reading Gene Expression ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: continuous.\n",
      "<150222> \tIs ascending: False.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 30 features & 1009 samples.\n",
      "<150222> Reading Pathway Expression ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: continuous.\n",
      "<150222> \tIs ascending: False.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 30 features & 1010 samples.\n",
      "<150222> Reading Protein Expression ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: continuous.\n",
      "<150222> \tIs ascending: False.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 30 features & 873 samples.\n",
      "<150222> Reading Pathology ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: binary.\n",
      "<150222> \tIs ascending: False.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 5 features & 1072 samples.\n",
      "<150222> Reading Phenotype ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: binary.\n",
      "<150222> \tIs ascending: False.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 30 features & 1142 samples.\n",
      "<150222> Reading Drug Sensitivity ...\n",
      "<150222> \tData: <class 'pandas.core.frame.DataFrame'>.\n",
      "<150222> \tData type: continuous.\n",
      "<150222> \tIs ascending: True.\n",
      "<150222> \tIndex axis: 0.\n",
      "<150222> \tIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29].\n",
      "<150222> \tIndex alias: [].\n",
      "<150222> \tRead 30 features & 645 samples.\n",
      "<150222> \n",
      "<150222> $\n",
      "<150222> $$\n",
      "<150222> $$$\n",
      "<150222> $$$$\n",
      "<150222> $$$$$\n",
      "<150222> Annotating component_9_vs_drug_sensitivity ...\n",
      "<150222> Target Component 9 (597 cols) and features (597 cols) have 597 shared columns.\n",
      "<150222> Dropping features with less than 3 unique values ...\n",
      "<150222> \tKept 30 features.\n",
      "<150222> Scoring (without parallelizing) ...\n",
      "<150223> Computing 0.95 CI using distributions built by 3 bootstraps ...\n",
      "<150223> \tBootstrapping top & bottom 10 features ...\n",
      "<150223> Computing P-value and FDR using 3 permutation test ...\n",
      "<150223> Scoring against permuted target (without parallelizing) ...\n",
      "<150223> \tScoring against permuted target (0/3) ...\n",
      "<150224> \tScoring against permuted target (1/3) ...\n",
      "<150224> \tScoring against permuted target (2/3) ...\n",
      "<150224> Computing P-value and FDR ...\n",
      "<150224> Plotting top & bottom 10 features ...\n",
      "<150224> Normalizing continuous target ...\n",
      "<150224> '-0-' normalizing pandas object on axis=None ...\n",
      "<150224> Normalizing continuous features ...\n",
      "<150224> '-0-' normalizing pandas object on axis=1 ...\n",
      "<150224> Plotting ...\n",
      "<150234> $$$$$\n",
      "<150234> $$$$\n",
      "<150234> $$$\n",
      "<150234> $$\n",
      "<150234> $\n",
      "<150234> \n",
      "<150234> \n",
      "<150234> $\n",
      "<150234> $$\n",
      "<150234> $$$\n",
      "<150234> $$$$\n",
      "<150234> $$$$$\n",
      "<150234> Annotating component_9_vs_variant ...\n",
      "<150234> Target Component 9 (737 cols) and features (737 cols) have 737 shared columns.\n",
      "<150234> Dropping features with less than 2 unique values ...\n",
      "<150234> \tKept 29 features.\n",
      "<150234> Scoring (without parallelizing) ...\n",
      "<150234> Computing 0.95 CI using distributions built by 3 bootstraps ...\n",
      "<150234> \tBootstrapping top & bottom 10 features ...\n",
      "<150235> Computing P-value and FDR using 3 permutation test ...\n",
      "<150235> Scoring against permuted target (without parallelizing) ...\n",
      "<150235> \tScoring against permuted target (0/3) ...\n",
      "<150235> \tScoring against permuted target (1/3) ...\n",
      "<150236> \tScoring against permuted target (2/3) ...\n",
      "<150236> Computing P-value and FDR ...\n",
      "<150236> Plotting top & bottom 10 features ...\n",
      "<150236> Normalizing continuous target ...\n",
      "<150236> '-0-' normalizing pandas object on axis=None ...\n",
      "<150236> Plotting ...\n",
      "<150245> $$$$$\n",
      "<150245> $$$$\n",
      "<150245> $$$\n",
      "<150245> $$\n",
      "<150245> $\n",
      "<150245> \n",
      "<150245> \n",
      "<150245> $\n",
      "<150245> $$\n",
      "<150245> $$$\n",
      "<150245> $$$$\n",
      "<150245> $$$$$\n",
      "<150245> Annotating component_9_vs_pathology ...\n",
      "<150245> Target Component 9 (750 cols) and features (750 cols) have 750 shared columns.\n",
      "<150245> Dropping features with less than 2 unique values ...\n",
      "<150245> \tKept 3 features.\n",
      "<150245> Scoring (without parallelizing) ...\n",
      "<150245> Computing 0.95 CI using distributions built by 3 bootstraps ...\n",
      "<150245> \tBootstrapping all 3 features ...\n",
      "<150245> Computing P-value and FDR using 3 permutation test ...\n",
      "<150245> Scoring against permuted target (without parallelizing) ...\n",
      "<150245> \tScoring against permuted target (0/3) ...\n",
      "<150245> \tScoring against permuted target (1/3) ...\n",
      "<150245> \tScoring against permuted target (2/3) ...\n",
      "<150245> Computing P-value and FDR ...\n",
      "<150245> Plotting all 3 features ...\n",
      "<150245> Normalizing continuous target ...\n",
      "<150245> '-0-' normalizing pandas object on axis=None ...\n",
      "<150245> Plotting ...\n",
      "<150247> $$$$$\n",
      "<150247> $$$$\n",
      "<150247> $$$\n",
      "<150247> $$\n",
      "<150247> $\n",
      "<150247> \n",
      "<150247> \n",
      "<150247> $\n",
      "<150247> $$\n",
      "<150247> $$$\n",
      "<150247> $$$$\n",
      "<150247> $$$$$\n",
      "<150247> Annotating component_9_vs_gene_expression ...\n",
      "<150247> Target Component 9 (750 cols) and features (750 cols) have 750 shared columns.\n",
      "<150247> Dropping features with less than 3 unique values ...\n",
      "<150247> \tKept 29 features.\n",
      "<150247> Scoring (without parallelizing) ...\n",
      "<150248> Computing 0.95 CI using distributions built by 3 bootstraps ...\n",
      "<150248> \tBootstrapping top & bottom 10 features ...\n",
      "<150249> Computing P-value and FDR using 3 permutation test ...\n",
      "<150249> Scoring against permuted target (without parallelizing) ...\n",
      "<150249> \tScoring against permuted target (0/3) ...\n",
      "<150250> \tScoring against permuted target (1/3) ...\n",
      "<150250> \tScoring against permuted target (2/3) ...\n",
      "<150251> Computing P-value and FDR ...\n",
      "<150251> Plotting top & bottom 10 features ...\n",
      "<150251> Normalizing continuous target ...\n",
      "<150251> '-0-' normalizing pandas object on axis=None ...\n",
      "<150251> Normalizing continuous features ...\n",
      "<150251> '-0-' normalizing pandas object on axis=1 ...\n",
      "<150251> Plotting ...\n",
      "<150304> $$$$$\n",
      "<150304> $$$$\n",
      "<150304> $$$\n",
      "<150304> $$\n",
      "<150304> $\n",
      "<150304> \n",
      "<150304> \n",
      "<150304> $\n",
      "<150304> $$\n",
      "<150304> $$$\n",
      "<150304> $$$$\n",
      "<150304> $$$$$\n",
      "<150304> Annotating component_9_vs_pathway_expression ...\n",
      "<150304> Target Component 9 (750 cols) and features (750 cols) have 750 shared columns.\n",
      "<150304> Dropping features with less than 3 unique values ...\n",
      "<150304> \tKept 30 features.\n",
      "<150304> Scoring (without parallelizing) ...\n",
      "<150305> Computing 0.95 CI using distributions built by 3 bootstraps ...\n",
      "<150305> \tBootstrapping top & bottom 10 features ...\n",
      "<150306> Computing P-value and FDR using 3 permutation test ...\n",
      "<150306> Scoring against permuted target (without parallelizing) ...\n",
      "<150306> \tScoring against permuted target (0/3) ...\n",
      "<150307> \tScoring against permuted target (1/3) ...\n",
      "<150308> \tScoring against permuted target (2/3) ...\n",
      "<150309> Computing P-value and FDR ...\n",
      "<150309> Plotting top & bottom 10 features ...\n",
      "<150309> Normalizing continuous target ...\n",
      "<150309> '-0-' normalizing pandas object on axis=None ...\n",
      "<150309> Normalizing continuous features ...\n",
      "<150309> '-0-' normalizing pandas object on axis=1 ...\n",
      "<150309> Plotting ...\n",
      "<150325> $$$$$\n",
      "<150325> $$$$\n",
      "<150325> $$$\n",
      "<150325> $$\n",
      "<150325> $\n",
      "<150325> \n",
      "<150325> \n",
      "<150325> $\n",
      "<150325> $$\n",
      "<150325> $$$\n",
      "<150325> $$$$\n",
      "<150325> $$$$$\n",
      "<150325> Annotating component_9_vs_gene_dependency ...\n",
      "<150325> Target Component 9 (371 cols) and features (371 cols) have 371 shared columns.\n",
      "<150325> Dropping features with less than 3 unique values ...\n",
      "<150325> \tKept 30 features.\n",
      "<150325> Scoring (without parallelizing) ...\n",
      "<150325> Computing 0.95 CI using distributions built by 3 bootstraps ...\n",
      "<150325> \tBootstrapping top & bottom 10 features ...\n",
      "<150326> Computing P-value and FDR using 3 permutation test ...\n",
      "<150326> Scoring against permuted target (without parallelizing) ...\n",
      "<150326> \tScoring against permuted target (0/3) ...\n",
      "<150326> \tScoring against permuted target (1/3) ...\n",
      "<150327> \tScoring against permuted target (2/3) ...\n",
      "<150327> Computing P-value and FDR ...\n",
      "<150327> Plotting top & bottom 10 features ...\n",
      "<150327> Normalizing continuous target ...\n",
      "<150327> '-0-' normalizing pandas object on axis=None ...\n",
      "<150327> Normalizing continuous features ...\n",
      "<150327> '-0-' normalizing pandas object on axis=1 ...\n",
      "<150327> Plotting ...\n",
      "<150339> $$$$$\n",
      "<150339> $$$$\n",
      "<150339> $$$\n",
      "<150339> $$\n",
      "<150339> $\n",
      "<150339> \n",
      "<150339> \n",
      "<150339> $\n",
      "<150339> $$\n",
      "<150339> $$$\n",
      "<150339> $$$$\n",
      "<150339> $$$$$\n",
      "<150339> Annotating component_9_vs_protein_expression ...\n",
      "<150339> Target Component 9 (687 cols) and features (687 cols) have 687 shared columns.\n",
      "<150339> Dropping features with less than 3 unique values ...\n",
      "<150339> \tKept 30 features.\n",
      "<150339> Scoring (without parallelizing) ...\n",
      "<150339> Computing 0.95 CI using distributions built by 3 bootstraps ...\n",
      "<150339> \tBootstrapping top & bottom 10 features ...\n",
      "<150341> Computing P-value and FDR using 3 permutation test ...\n",
      "<150341> Scoring against permuted target (without parallelizing) ...\n",
      "<150341> \tScoring against permuted target (0/3) ...\n",
      "<150342> \tScoring against permuted target (1/3) ...\n",
      "<150342> \tScoring against permuted target (2/3) ...\n",
      "<150343> Computing P-value and FDR ...\n",
      "<150343> Plotting top & bottom 10 features ...\n",
      "<150343> Normalizing continuous target ...\n",
      "<150343> '-0-' normalizing pandas object on axis=None ...\n",
      "<150343> Normalizing continuous features ...\n",
      "<150343> '-0-' normalizing pandas object on axis=1 ...\n",
      "<150343> Plotting ...\n"
     ]
    }
   ],
   "source": [
    "for feature_bundle_name, feature_bundle in feature_bundles.items():\n",
    "    ccal.make_association_panels(target_bundle, feature_bundle,\n",
    "                                 n_features=10, n_jobs=1, n_samplings=3, n_permutations=3,\n",
    "                                 dpi=10,\n",
    "                                 filepath_prefix='result/make_association_panels/{}_'.format(feature_bundle_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test make_association_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ccal.support.VERBOSE = False\n",
    "\n",
    "# Test continuous, categorical, and binary target\n",
    "for n_targert_categories in [None, 10, 2]:\n",
    "    \n",
    "    if n_targert_categories:\n",
    "        if n_targert_categories == 2:  # Test binary category\n",
    "            target_type = 'binary'\n",
    "            \n",
    "        elif n_targert_categories > 2:  # Test categorical category\n",
    "            target_type = 'categorical'\n",
    "            \n",
    "    else:  # Test continuous target\n",
    "        target_type = 'continuous'\n",
    "        \n",
    "    # Test continuous, categorical, and binary features\n",
    "    for n_feature_categories in [None, 10, 2]:\n",
    "        \n",
    "        if n_feature_categories:\n",
    "            if n_feature_categories == 2:  # Test binary features\n",
    "                feature_type = 'binary'\n",
    "                \n",
    "            elif n_feature_categories > 2:  # Test categorical features\n",
    "                feature_typef = 'categorical'\n",
    "                \n",
    "        else:  # Test continuous features\n",
    "            feature_type = 'continuous'\n",
    "\n",
    "        # Test with varying number of features\n",
    "        for n_features in [1, 2, 10, 100, 1000]:\n",
    "            \n",
    "            # Test with varying number of samples\n",
    "            for n_samples in [1, 2, 3, 10, 100, 1000]:\n",
    "\n",
    "                # Simualte target\n",
    "                simulated_target = ccal.simulate_dataframe_or_series(1,\n",
    "                                                                     n_samples,\n",
    "                                                                     n_categories=n_targert_categories)\n",
    "                \n",
    "                # Simulate features\n",
    "                simulated_features = ccal.simulate_dataframe_or_series(n_features,\n",
    "                                                                       n_samples,\n",
    "                                                                       n_categories=n_feature_categories)\n",
    "                \n",
    "                # Test varying number of parallel jobs\n",
    "                for n_jobs in [1, 2, 4]:\n",
    "                    \n",
    "                    # Test varying numbner of samplings\n",
    "                    for n_samplings in [1, 3]: \n",
    "\n",
    "                        # Test varying number of permutations\n",
    "                        for n_permutations in [1, 2, 10]:\n",
    "\n",
    "                            title = 'target:{}&features:{}&{}features&{}samples&{}samplings&{}permutations'.format(target_type,\n",
    "                                                                                                                   feature_type,\n",
    "                                                                                                                   n_features,\n",
    "                                                                                                                   n_samples,\n",
    "                                                                                                                   n_samplings,\n",
    "                                                                                                                   n_permutations)\n",
    "                            print(title)\n",
    "\n",
    "                            # Test\n",
    "                            ccal.make_association_panel(simulated_target, simulated_features,\n",
    "                                                        target_type=target_type, feature_type=feature_type, \n",
    "                                                        n_samplings=n_samplings, n_permutations=n_permutations,\n",
    "                                                        title=title,                                                   \n",
    "                                                        filepath_prefix='result/make_association_panel/{}'.format(title))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
