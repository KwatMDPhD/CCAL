{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "==================== Computational Cancer Analysis Library ====================\n",
      "===============================================================================\n",
      "<13:47:42> Checking dependencies ...\n",
      "<13:47:42> Using the following packages:\n",
      "<13:47:42> \tmatplotlib (v1.5.1)\n",
      "<13:47:42> \tnumpy (v1.10.4)\n",
      "<13:47:42> \tpandas (v0.18.0)\n",
      "<13:47:42> \trpy2 (v2.7.9)\n",
      "<13:47:42> \tscikit-learn (v0.17.1)\n",
      "<13:47:42> \tscipy (v0.17.0)\n",
      "<13:47:42> \tseaborn (v0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cProfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "              \n",
    "sys.path.insert(0, '../../')\n",
    "import ccal\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'svg',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "# TODO pythonize bcv\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.numpy2ri import numpy2ri\n",
    "\n",
    "ro.conversion.py2ri = numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "mass = importr('MASS')\n",
    "\n",
    "from ccal.support import drop_nan_columns, add_jitter\n",
    "\n",
    "def rbcv(x):\n",
    "    \"\"\"\n",
    "    :param x: array-like, (n_samples,)\n",
    "    :return: float, bandwidth\n",
    "    \"\"\"\n",
    "    bandwidth = np.array(mass.bcv(x))[0]\n",
    "    return bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def information_coefficient(x, y, z=None, n_grid=25, vector_data_types=None, n_perm=0, adaptive=True, alpha=0.05,\n",
    "                            perm_alpha=0.05):\n",
    "    \"\"\"\n",
    "    :param x: array-like, (n_samples,)\n",
    "    :param y: array-like, (n_samples,)\n",
    "    :param z: array-like, (n_samples,), optional, variable on which to condition\n",
    "    :param n_grid: int, number of grid points at which to evaluate kernel density\n",
    "    :param vector_data_types: str, 3 chars of 'c' (continuous), 'u' (unordered discrete), or 'o' (ordered discrete)\n",
    "    :param n_perm: int, >0 will return a p-value in addition to the information coefficient\n",
    "    :param adaptive: bool, quit permutations after achieving a confidence that the p-value is above (or below) alpha\n",
    "    :param alpha: float, threshold empirical p-value for significance of IC\n",
    "    :param perm_alpha: float, threshold probability for terminating adaptive permutation\n",
    "    :return: float (and float), information coefficient, and the empirical p-value if n_perm > 0\n",
    "                If adaptive, the accuracy of the empirical p-value will vary: values closer to alpha will be estimated\n",
    "                more precisely, while values obviously greater or less than alpha will be estimated less precisely.\n",
    "    \"\"\"\n",
    "    vectors = [x, y]\n",
    "    if z:\n",
    "        vectors.append(z)\n",
    "        x, y, z = add_jitter(drop_nan_columns(vectors))\n",
    "    else:\n",
    "        x, y = add_jitter(drop_nan_columns(vectors))\n",
    "\n",
    "    if not vector_data_types:\n",
    "        # TODO: guess variable types\n",
    "        vector_data_types = 'c' * len(vectors)\n",
    "    elif len(vector_data_types) is not len(vectors):\n",
    "        raise ValueError('Number of specified variable types does not match number of vectors.')\n",
    "\n",
    "    if len(x) <= len(vector_data_types):\n",
    "        return 0\n",
    "\n",
    "    \n",
    "\n",
    "    mi = mutual_information(x, y, z=z,\n",
    "                            n_grid=n_grid, vector_data_types=vector_data_types, bandwidth_scaling=bandwidth_scaling)\n",
    "\n",
    "    ic_sign = np.sign(rho)\n",
    "    ic = ic_sign * np.sqrt(1 - np.exp(- 2 * mi))\n",
    "\n",
    "    if n_perm:\n",
    "        n_more_extreme = 0\n",
    "        trials = 0\n",
    "        for i in range(n_perm):\n",
    "            trials += 1\n",
    "            # The question is whether I want to have\n",
    "            # a certain width of confidence interval around my estimate of the pval\n",
    "            # or just a certain confidence that the pval is greater than 0.05 (current solution)\n",
    "            pm_x = np.random.permutation(x)\n",
    "            pm_rho, p = pearsonr(pm_x, y)\n",
    "            pm_rho2 = abs(pm_rho)\n",
    "            pm_bandwidth_scaling = (1 + (-0.75) * pm_rho2)\n",
    "            pm_mi = mutual_information(pm_x, y, z, n_grid=n_grid,\n",
    "                                       vector_data_types=vector_data_types, bandwidth_scaling=pm_bandwidth_scaling)\n",
    "            pm_ic_sign = np.sign(pm_rho)\n",
    "            pm_ic = pm_ic_sign * np.sqrt(1 - np.exp(- 2 * pm_mi))\n",
    "            if (pm_ic <= ic and ic < 0) or (0 < ic and ic <= pm_ic):\n",
    "                n_more_extreme += 1\n",
    "            if adaptive:\n",
    "                ge_binom_p = binom_test(n_more_extreme, i + 1, alpha, alternative='greater')\n",
    "                # * 2 because what I'm doing is two-sided testing in both directions\n",
    "                if ge_binom_p * 2 < perm_alpha:\n",
    "                    break\n",
    "                le_binom_p = binom_test(n_more_extreme, i + 1, alpha, alternative='less')\n",
    "                if le_binom_p * 2 < perm_alpha:\n",
    "                    break\n",
    "        p_value = n_more_extreme / float(trials)\n",
    "        return ic, p_value\n",
    "    else:\n",
    "        return ic\n",
    "\n",
    "\n",
    "# TODO: understand the math\n",
    "def mutual_information(x, y, z=None, n_grid=25, vector_data_types=None, bandwidth_scaling=None):\n",
    "    \"\"\"\n",
    "    :param x: array-like, (n_samples,)\n",
    "    :param y: array-like, (n_samples,)\n",
    "    :param z: array-like, (n_samples,), optional, variable on which to condition\n",
    "    :param n_grid: int, number of grid points at which to evaluate kernel density\n",
    "    :param vector_data_types: str, 3 chars of 'c' (continuous), 'u' (unordered discrete), or 'o' (ordered discrete)\n",
    "    :param bandwidth_scaling: float,\n",
    "    :return: float, information coefficient\n",
    "    \"\"\"\n",
    "    vectors = [x, y]\n",
    "    if z:\n",
    "        vectors.append(z)\n",
    "\n",
    "    grids = [np.linspace(v.min(), v.max(), n_grid) for v in vectors]\n",
    "    mesh_grids = np.meshgrid(*grids)\n",
    "    grid_shape = tuple([n_grid] * len(vectors))\n",
    "    grid = np.vstack([mesh_grid.flatten() for mesh_grid in mesh_grids])\n",
    "    delta = np.array([rbcv(q) for q in vectors]).reshape((len(vectors),)) / 4\n",
    "    if bandwidth_scaling:\n",
    "        delta *= bandwidth_scaling\n",
    "    kde = KDEMultivariate(vectors, bw=delta, var_type=vector_data_types)\n",
    "    p_joint = kde.pdf(grid).reshape(grid_shape) + np.finfo(float).eps\n",
    "    ds = [grid[1] - grid[0] for grid in grids]\n",
    "    ds_prod = np.prod(ds)\n",
    "    p_joint /= (p_joint.sum() * ds_prod)\n",
    "    h_joint = - np.sum(p_joint * np.log(p_joint)) * ds_prod\n",
    "    \n",
    "    dx = ds[0]\n",
    "    dy = ds[1]\n",
    "    if z:\n",
    "        dz = ds[2]\n",
    "        pxz = p_joint.sum(axis=1) * dy\n",
    "        pyz = p_joint.sum(axis=0) * dx\n",
    "        pz = p_joint.sum(axis=(0, 1)) * dx * dy\n",
    "        hxz = -np.sum(pxz * np.log(pxz)) * dx * dz\n",
    "        hyz = -np.sum(pyz * np.log(pyz)) * dy * dz\n",
    "        hz = -np.sum(pz * np.log(pz)) * dz\n",
    "        cmi = hxz + hyz - h_joint - hz\n",
    "        return cmi\n",
    "    else:\n",
    "        dx = ds[0]\n",
    "        dy = ds[1]\n",
    "        px = p_joint.sum(axis=1) * dy\n",
    "        py = p_joint.sum(axis=0) * dx\n",
    "        hx = -np.sum(px * np.log(px)) * dx\n",
    "        hy = -np.sum(py * np.log(py)) * dy\n",
    "        mi = hx + hy - h_joint\n",
    "        return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = None\n",
    "ngrid = 25\n",
    "vectors = [np.random.random_sample(1000), np.random.random_sample(1000)]\n",
    "vector_data_types = 'cc'\n",
    "\n",
    "if z:\n",
    "    x, y = vectors\n",
    "    vectors.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_grids = [np.linspace(v.min(), v.max(), ngrid) for v in vectors]\n",
    "vector_grids = np.linspace(0, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.meshgrid(*[vector_grids, vector_grids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kde(vectors, vector_data_types, bandwidth_scaling=None):\n",
    "    bandwidths = np.array([rbcv(v) for v in vectors])\n",
    "    bandwidths /= 4\n",
    "    if bandwidth_scaling:\n",
    "        bandwidths *= bandwidth_scaling\n",
    "    kde = KDEMultivariate(vectors, vector_data_types, bw=bandwidths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def x(vectors):\n",
    "    delta = np.array([rbcv(z) for z in [x, y]]).reshape((2,)) / 4\n",
    "    if bandwidth_scaling:\n",
    "        delta *= bandwidth_scaling\n",
    "    kde = KDEMultivariate(xy, bw=delta, var_type=var_type)\n",
    "\n",
    "    fxy = kde.pdf(grid).reshape((n_grid, n_grid)).T + np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cProfile.run('KDEMultivariate([x,y], bw=[0.06199576, 0.05991138], var_type=\"cc\")', sort=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ns, runtimes = ccal.support.runtime(information_coefficient_old, 1000)\n",
    "sns.pointplot(ns, runtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref = ccal.support.read_gct('/Users/Kwat/Downloads/CCLE.rpkm.v2.SELECTED_SIGNATURES.v2.gct').ix['KRAS_SALE_Late_Comp_C8_9', :]\n",
    "features = ccal.support.read_gct('/Users/Kwat/Downloads/ccle_mut_cna.gct')\n",
    "ccal.analyze.rank_features_against_reference(features, ref, nsampling=1,\n",
    "                                             nperm=1, title='Title', annotation_header='IC' + ' ' * 21 + 'P-val' + ' ' * 4 + 'FDR',\n",
    "                                             output_prefix='/Users/Kwat/Desktop/ola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nrow, ncol = 2, 1000\n",
    "features = ccal.support.make_random_features(nrow, ncol)\n",
    "ref = ccal.support.make_random_features(1, ncol)\n",
    "ccal.analyze.rank_features_against_reference(features, ref, nsampling=2,\n",
    "                                             nperm=2, title='Title', annotation_header='IC' + ' ' * 21 + 'P-val' + ' ' * 4 + 'FDR',\n",
    "                                             output_prefix='/Users/Kwat/Desktop/ola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ccal.support.VERBOSE = False\n",
    "for r in range(1, 500, 100):\n",
    "    for c in range(1, 500, 100):\n",
    "        features = ccal.support.make_random_features(r, c)\n",
    "        ref = ccal.support.make_random_features(1, c)\n",
    "        ccal.analyze.rank_features_against_reference(features, ref, nsampling=2,\n",
    "                                                     nperm=2, nfeatures=0, title='Continuous {} x {}'.format(r, c))\n",
    "        \n",
    "n_category = 10\n",
    "for r in range(1, 500, 100):\n",
    "    for c in range(1, 500, 100):\n",
    "        features = ccal.support.make_random_features(r, c, n_category=n_category)\n",
    "        ref = ccal.support.make_random_features(1, c, n_category=n_category)\n",
    "        ccal.analyze.rank_features_against_reference(features, ref, ref_type='categorical',\n",
    "                                                     nsampling=2, nperm=2, nfeatures=0, title='Categorical {} x {}'.format(r, c))\n",
    "\n",
    "n_category = 2\n",
    "for r in range(1, 500, 100):\n",
    "    for c in range(1, 500, 100):\n",
    "        features = ccal.support.make_random_features(r, c, n_category=n_category)\n",
    "        ref = ccal.support.make_random_features(1, c, n_category=n_category)\n",
    "        ccal.analyze.rank_features_against_reference(features, ref, ref_type='binary',\n",
    "                                                     nsampling=2, nperm=2, nfeatures=0, title='Binary {} x {}'.format(r, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.random_sample(10)\n",
    "y = np.random.random_sample(10)\n",
    "print(ccal.information.information_coefficient(x, y))\n",
    "\n",
    "x = np.random.random_sample(10)\n",
    "y = np.random.random_sample(11)\n",
    "try:\n",
    "    ccal.information.information_coefficient(x, y)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "x = np.random.random_sample(10)\n",
    "x[1] = None\n",
    "y = np.random.random_sample(10)\n",
    "y[2] = None\n",
    "print(ccal.information.information_coefficient(x, y))\n",
    "\n",
    "x = np.random.random_sample(10)\n",
    "x[1] = None\n",
    "y = np.random.random_sample(10)\n",
    "y[2] = None\n",
    "y[6] = None\n",
    "print(ccal.information.information_coefficient(x, y))\n",
    "\n",
    "x = np.random.random_sample(10)\n",
    "x[1] = None\n",
    "x[3] = None\n",
    "x[5] = None\n",
    "y = np.random.random_sample(10)\n",
    "y[2] = None\n",
    "y[4] = None\n",
    "print(ccal.information.information_coefficient(x, y))\n",
    "\n",
    "x = np.array([12.517, 14.706, np.nan, 14.12, np.nan, np.nan, np.nan, 12.255])\n",
    "y = np.array([0.98246356, 0.97525171, 0.77744759, 0.64084311, 0.4405853, 0.43827196, 0.12447757, 0.08116039])\n",
    "print(ccal.information.information_coefficient(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make simulation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_value(df, inVal, outVal):\n",
    "    # Add value in cluster\n",
    "    # Set inVal or outVal to be None when not updating it\n",
    "    \n",
    "    for i,(n,s) in enumerate(df.iterrows()):\n",
    "        #print('add_value:',i)\n",
    "        for j,c in enumerate(s.index):\n",
    "            if inVal and n==c:\n",
    "                df.iloc[i,j]=inVal\n",
    "            if outVal and n!=c:\n",
    "                df.iloc[i,j]=outVal\n",
    "\n",
    "def add_noise(df,inMu,inSigma,outMu,outSigma):\n",
    "    # Add noise\n",
    "    \n",
    "    for i,(n,s) in enumerate(df.iterrows()):\n",
    "        #print('add_noise:',i)\n",
    "        for j,c in enumerate(s.index):\n",
    "            if (inMu or inSigma) and n==c:\n",
    "                df.iloc[i,j]+=random.gauss(inMu,inSigma)\n",
    "            if (outMu or outSigma) and n!=c:\n",
    "                df.iloc[i,j]+=random.gauss(outMu,outSigma)\n",
    "\n",
    "def mix(df,k,mix):\n",
    "    # Mix cluster values to nonclusters and vice versa\n",
    "    \n",
    "    assert k!=0, print('k cannot be 0')\n",
    "    \n",
    "    # Get the number of values in a cluster\n",
    "    n_k_val=len(df.columns)*len(df.index)/k\n",
    "    #print('n_k_val:',n_k_val)\n",
    "    \n",
    "    # Count\n",
    "    c=0\n",
    "    while c<mix*n_k_val:\n",
    "        \n",
    "        # Pick 1st random index and column\n",
    "        r_idx0=random.randint(0,len(df.index)-1)\n",
    "        r_col0=random.randint(0,len(df.columns)-1)\n",
    "\n",
    "        # If index and column locate inside a cluster\n",
    "        if df.index[r_idx0]==df.columns[r_col0]:    \n",
    "            \n",
    "            # Get cluster value located\n",
    "            pick0=df.iloc[r_idx0,r_col0]\n",
    "            \n",
    "            # Pick 2nd random index and column\n",
    "            r_idx1=random.randint(0,len(df.index)-1)\n",
    "            r_col1=random.randint(0,len(df.columns)-1)\n",
    "            \n",
    "            # If index and column locate outside a cluster\n",
    "            if df.index[r_idx1]!=df.columns[r_col1]:    \n",
    "\n",
    "                # Get non-cluster value located\n",
    "                pick1=df.iloc[r_idx1,r_col1]\n",
    "\n",
    "                # Swap\n",
    "                df.iloc[r_idx0,r_col0]=pick1\n",
    "                df.iloc[r_idx1,r_col1]=pick0\n",
    "                \n",
    "                # Count\n",
    "                c+=1\n",
    "                \n",
    "                #print('Swapped (%s,%s) & (%s,%s)'%(df.index[r_idx0],df.columns[r_col0],df.index[r_idx1],df.columns[r_col1]))\n",
    "\n",
    "def initialize_simulation_df(df,inVal,inMu,inSigma,outVal,outMu,outSigma,mix):\n",
    "    # Initialize values in and out of a cluster and add noise\n",
    "    \n",
    "    t0=time()\n",
    "    \n",
    "    # For each row\n",
    "    for i,(n,s) in enumerate(df.iterrows()):\n",
    "        print('initialize_simulation_df:',i)\n",
    "        \n",
    "        # For each column\n",
    "        for j,c in enumerate(s.index):\n",
    "            r=random.random()\n",
    "            \n",
    "            if mix and r<=mix:\n",
    "                # Mix\n",
    "                if n==c:\n",
    "                    # In cluster gets out-value\n",
    "                    df.iloc[i,j]=outVal\n",
    "                    if outMu or outSigma:\n",
    "                        df.iloc[i,j]+=random.gauss(outMu,outSigma)\n",
    "                else:\n",
    "                    # Out cluster gets in-value\n",
    "                    df.iloc[i,j]=inVal\n",
    "                    if inMu or inSigma:\n",
    "                        df.iloc[i,j]+=random.gauss(inMu,inSigma) \n",
    "            else:\n",
    "                # No mix\n",
    "                if n==c:\n",
    "                    # In cluster gets in-value\n",
    "                    df.iloc[i,j]=inVal\n",
    "                    if inMu or inSigma:\n",
    "                        df.iloc[i,j]+=random.gauss(inMu,inSigma)\n",
    "                else:\n",
    "                    # Out cluster gets out-value\n",
    "                    df.iloc[i,j]=outVal\n",
    "                    if outMu or outSigma:\n",
    "                        df.iloc[i,j]+=random.gauss(outMu,outSigma)\n",
    "    print('initialize_simulation_df: done in %0.3fs.'%(time()-t0))\n",
    "\n",
    "def plot_mtrx(mtrx):\n",
    "    # Plot simulation matrix\n",
    "    \n",
    "    plt.imshow(mtrx,interpolation='nearest',cmap=plt.cm.ocean)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "def make_mtrx_sample_x_variable_simulation(n_sample,\n",
    "                                           n_var,\n",
    "                                           k,\n",
    "                                           val_in,\n",
    "                                           val_out,\n",
    "                                           noise_in_mu=None,\n",
    "                                           noise_in_sigma=None,\n",
    "                                           noise_out_mu=None,\n",
    "                                           noise_out_sigma=None,\n",
    "                                           noise_mix=None,\n",
    "                                           prefix_out_f=None,\n",
    "                                           suffix_out_f=None,\n",
    "                                           plot=False):\n",
    "    \"\"\"\n",
    "    Make sample x variable matrix\n",
    "    \"\"\"\n",
    "    assert k != 0, 'k cannot be 0'\n",
    "    assert k <= n_var,'k cannot be greater than n_var'\n",
    "    \n",
    "    # Make an empty sample x variable matrix filled with 0\n",
    "    mtrx_sample_x_var = pd.DataFrame(index=range(n_sample), columns=range(n_var)).fillna(0)\n",
    "\n",
    "    # Slice dataframe index and column and make lists of dataframe indexes and columns for each index and column slice\n",
    "    list_index_slice = toolK.slice_list(mtrx_sample_x_var.index, k)\n",
    "    list_column_slice = toolK.slice_list(mtrx_sample_x_var.columns, k)\n",
    "\n",
    "    # Make index and column slice x dataframe indexes dictionaries\n",
    "    dict_index_slice = {}\n",
    "    for i, l in enumerate(list_index_slice):\n",
    "        dict_index_slice[i] = l\n",
    "    dict_column_slice = {}\n",
    "    for i, l in enumerate(list_column_slice):\n",
    "        dict_column_slice[i] = l\n",
    "\n",
    "    # Set dataframe index and column to be index and column slice indices respectively\n",
    "    index=list(mtrx_sample_x_var.index)\n",
    "    for i,l in dict_index_slice.items():\n",
    "        for j in l:\n",
    "            index[j]=i\n",
    "    mtrx_sample_x_var.index=index\n",
    "    columns=list(mtrx_sample_x_var.columns)\n",
    "    for i,l in dict_column_slice.items():\n",
    "        for j in l:\n",
    "            columns[j]=i\n",
    "    mtrx_sample_x_var.columns=columns\n",
    "\n",
    "    # Initialize simulation matrix\n",
    "    initialize_simulation_df(mtrx_sample_x_var,val_in,noise_in_mu,noise_in_sigma,val_out,noise_out_mu,noise_out_sigma,noise_mix)\n",
    "    \n",
    "    # Save\n",
    "    if prefix_out_f:        \n",
    "        mtrx_sample_x_var.to_csv(prefix_out_f+'_sample_%s_var_%s_k_%s_mix_%s_%s'%(n_sample,n_var,k,noise_mix,suffix_out_f),sep='\\t')\n",
    "    \n",
    "    # Plot\n",
    "    if plot:\n",
    "        plot_mtrx(mtrx_sample_x_var)\n",
    "\n",
    "# Make simulation matrix\n",
    "\n",
    "# Set number of samples\n",
    "list_n_sample = [100, 500, 1000, 5000]\n",
    "# Set number of variables\n",
    "list_n_var = [100, 500, 1000, 5000]\n",
    "# Set values in clusters\n",
    "val_in = 1\n",
    "# Set values out of clusters\n",
    "val_out = 0\n",
    "# Set Ks\n",
    "list_k = [1, 2, 3, 4, 5, 6, 10, 15, 20, 25]\n",
    "# Set the fractions of cluster values to be swapped between clusters and nonclusters\n",
    "list_noise_mix = [0, 0.05, 0.1, 0.2]\n",
    "# Set noise in clusters\n",
    "noise_in_mu = 0\n",
    "noise_in_sigma = 0.1 * noise_in_mu\n",
    "# Set noise out of clusters\n",
    "noise_out_mu = 0\n",
    "noise_out_sigma = 0.1*noise_out_mu\n",
    "\n",
    "# Simulate\n",
    "for sample in list_n_sample:\n",
    "    print('sample:',sample)\n",
    "    \n",
    "    for var in list_n_var:\n",
    "        print('\\tvar:',var)\n",
    "        \n",
    "        for k in list_k:\n",
    "            print('\\t\\tk:',k)\n",
    "            \n",
    "            for noise_mix in list_noise_mix:\n",
    "                print('\\t\\t\\tnoise_mix:',noise_mix)\n",
    "                \n",
    "                make_mtrx_sample_x_variable_simulation(sample,\n",
    "                                                       var,\n",
    "                                                       k,\n",
    "                                                       val_in,\n",
    "                                                       val_out,\n",
    "                                                       noise_mix=noise_mix,\n",
    "                                                       prefix_out_f='/cellar/users/hyeerna/aLL/mtrx_sample_x_var_simulation/test/',\n",
    "                                                       suffix_out_f='sfx',\n",
    "                                                       plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
