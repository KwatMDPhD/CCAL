{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "==================== Computational Cancer Analysis Library ====================\n",
      "===============================================================================\n",
      "<22:19:01.560207> Checking dependencies ...\n",
      "<22:19:01.562632> Using the following packages:\n",
      "<22:19:01.564378> \tmatplotlib (v1.5.1)\n",
      "<22:19:01.564396> \tnumpy (v1.10.4)\n",
      "<22:19:01.564405> \tpandas (v0.18.0)\n",
      "<22:19:01.564426> \trpy2 (v2.7.9)\n",
      "<22:19:01.564435> \tscikit-learn (v0.17.1)\n",
      "<22:19:01.564442> \tscipy (v0.17.0)\n",
      "<22:19:01.564449> \tseaborn (v0.7.0)\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (information.py, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"../../ccal/information.py\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    <<<<<<< HEAD\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, cophenet\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "import ccal\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'svg',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ccal.support.read_gct('/Users/Kwat/Downloads/v22_pub.gct')\n",
    "\n",
    "component_x_cellline = ccal.support.read_gct('/Users/Kwat/Downloads/CCLE.rpkm.v2.SELECTED_SIGNATURES.v2.gct')\n",
    "ref = component_x_cellline.ix['KRAS_SALE_Late_Comp_C1_9', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_random = ccal.support.make_random_features(10, 10)\n",
    "ref_random = ccal.support.make_random_features(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_random.index = random.sample(ref.index.tolist(), ref_random.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ccal.analyze.rank_features_against_reference(features, ref_random, n_sampling=1, n_perm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "from scipy.stats import binom_test\n",
    "# TODO: pythonize bcv\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.numpy2ri import numpy2ri\n",
    "\n",
    "ro.conversion.py2ri = numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "mass = importr('MASS')\n",
    "\n",
    "\n",
    "def information_coefficient(x, y, z=None, n_grid=25, vector_data_type=None, n_perm=0, adaptive=True, alpha=0.05,\n",
    "                            perm_alpha=0.05):\n",
    "    \"\"\"\n",
    "    :param x: array-like, (n_samples,)\n",
    "    :param y: array-like, (n_samples,)\n",
    "    :param z: array-like, (n_samples,), optional, variable on which to condition\n",
    "    :param n_grid: int, number of grid points at which to evaluate kernel density\n",
    "    :param vector_data_types: str, 3 chars of 'c' (continuous), 'u' (unordered discrete), or 'o' (ordered discrete)\n",
    "    :param n_perm: int, >0 will return a p-value in addition to the information coefficient\n",
    "    :param adaptive: bool, quit permutations after achieving a specified confidence that the p-value is above (or below) alpha\n",
    "    :param alpha: float, threshold empirical p-value for significance of IC\n",
    "    :param perm_alpha: float, threshold probability for terminating adaptive permutation\n",
    "    :return: float and float, information coefficient, and the empirical p-value if n_perm > 0\n",
    "                Note that if adaptive, the accuracy of the empirical p-value will vary: values closer to alpha will be estimated\n",
    "                more precisely, while values obviously greater or less than alpha will be estimated less precisely.\n",
    "    \"\"\"\n",
    "    vectors = [x, y]\n",
    "    if z:\n",
    "        vectors.append(z)\n",
    "        x, y, z = drop_nan_columns(vectors)\n",
    "    else:\n",
    "        x, y = drop_nan_columns(vectors)\n",
    "        \n",
    "    rho, p = pearsonr(x, y)\n",
    "    print(rho, p)\n",
    "    \n",
    "    rho2 = abs(rho)\n",
    "    bandwidth_scaling = 1 + (-0.75) * rho2\n",
    "    \n",
    "    mi = mutual_information(x, y, z=z, n_grid=n_grid,\n",
    "                            vector_data_types=vector_data_type, bandwidth_scaling=bandwidth_scaling)\n",
    "    ic_sign = np.sign(rho)\n",
    "    ic = ic_sign * np.sqrt(1 - np.exp(- 2 * mi))\n",
    "\n",
    "    if n_perm:\n",
    "        n_more_extreme = 0\n",
    "        trials = 0\n",
    "        for i in range(n_perm):\n",
    "            trials += 1\n",
    "            # The question is whether I want to have\n",
    "            # a certain width of confidence interval around my estimate of the pval\n",
    "            # or just a certain confidence that the pval is greater than 0.05 (current solution)\n",
    "            pm_x = np.random.permutation(x)\n",
    "            pm_rho, p = pearsonr(pm_x, y)\n",
    "            pm_rho2 = abs(pm_rho)\n",
    "            pm_bandwidth_scaling = (1 + (-0.75) * pm_rho2)\n",
    "            pm_mi = mutual_information(pm_x, y, z, n_grid=n_grid,\n",
    "                                       vector_data_types=vector_data_type, bandwidth_scaling=pm_bandwidth_scaling)\n",
    "            pm_ic_sign = np.sign(pm_rho)\n",
    "            pm_ic = pm_ic_sign * np.sqrt(1 - np.exp(- 2 * pm_mi))\n",
    "            if (pm_ic <= ic and ic < 0) or (0 < ic and ic <= pm_ic):\n",
    "                n_more_extreme += 1\n",
    "            if adaptive:\n",
    "                ge_binom_p = binom_test(n_more_extreme, i + 1, alpha, alternative='greater')\n",
    "                # * 2 because what I'm doing is two-sided testing in both directions\n",
    "                if ge_binom_p * 2 < perm_alpha:\n",
    "                    break\n",
    "                le_binom_p = binom_test(n_more_extreme, i + 1, alpha, alternative='less')\n",
    "                if le_binom_p * 2 < perm_alpha:\n",
    "                    break\n",
    "        p_value = n_more_extreme / float(trials)\n",
    "        return ic, p_value\n",
    "    else:\n",
    "        return ic\n",
    "\n",
    "\n",
    "# TODO: understand the math\n",
    "def mutual_information(x, y, z=None, n_grid=25, vector_data_types=None, bandwidth_scaling=None):\n",
    "    \"\"\"\n",
    "    :param x: array-like, (n_samples,)\n",
    "    :param y: array-like, (n_samples,)\n",
    "    :param z: array-like, (n_samples,), optional, variable on which to condition\n",
    "    :param n_grid: int, number of grid points at which to evaluate kernel density\n",
    "    :param vector_data_types: str, 3 chars of 'c' (continuous), 'u' (unordered discrete), or 'o' (ordered discrete)\n",
    "    :param bandwidth_scaling: float,\n",
    "    :return: float, information coefficient\n",
    "    \"\"\"\n",
    "    vectors = [x, y]\n",
    "    if z:\n",
    "        vectors.append(z)\n",
    "        x, y, z = drop_nan_columns(vectors)\n",
    "    else:\n",
    "        x, y = drop_nan_columns(vectors)\n",
    "        \n",
    "    if not vector_data_types:\n",
    "        # TODO: guess variable types\n",
    "        vector_data_types = 'c' * len(vectors)\n",
    "    elif len(vector_data_types) is not len(vectors):\n",
    "        raise ValueError('Number of specified variable types does not match number of vectors.')\n",
    "\n",
    "    # Keep only columns that are not NaN in all vectors, and add jitter to the filtered vectors\n",
    "    not_nan_filter = [True] * vectors[0].size\n",
    "    for v in vectors:\n",
    "        not_nan_filter &= ~np.isnan(v)\n",
    "    if not_nan_filter.sum() < 3:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(len(vectors)):\n",
    "            vectors[i] = vectors[i][not_nan_filter]\n",
    "            vectors[i] += np.random.random_sample(vectors[i].size) * 1E-10\n",
    "    print(vectors)\n",
    "\n",
    "    grids = [np.linspace(v.min(), v.max(), n_grid) for v in vectors]\n",
    "    print('grids', grids)\n",
    "    mesh_grids = np.meshgrid(*grids)\n",
    "    grid_shape = tuple([n_grid] * len(vectors))\n",
    "    print(grid_shape)\n",
    "    grid = np.vstack([mesh_grid.flatten() for mesh_grid in mesh_grids])\n",
    "    print('grid', grid)\n",
    "    delta = np.array([rbcv(q) for q in vectors]).reshape((len(vectors),)) / 4\n",
    "    print('delta', delta)\n",
    "    if bandwidth_scaling:\n",
    "        delta *= bandwidth_scaling\n",
    "        print('delta', delta)\n",
    "    kde = KDEMultivariate(vectors, bw=delta, var_type=vector_data_types)\n",
    "    p_joint = kde.pdf(grid).reshape(grid_shape) + np.finfo(float).eps\n",
    "    print('p_joint', p_joint)\n",
    "    ds = [grid[1] - grid[0] for grid in grids]\n",
    "    ds_prod = np.prod(ds)\n",
    "    p_joint /= (p_joint.sum() * ds_prod)\n",
    "    h_joint = - np.sum(p_joint * np.log(p_joint)) * ds_prod\n",
    "    dx = ds[0]\n",
    "    dy = ds[1]\n",
    "    if z:\n",
    "        dz = ds[2]\n",
    "        pxz = p_joint.sum(axis=1) * dy\n",
    "        pyz = p_joint.sum(axis=0) * dx\n",
    "        pz = p_joint.sum(axis=(0, 1)) * dx * dy\n",
    "        hxz = -np.sum(pxz * np.log(pxz)) * dx * dz\n",
    "        hyz = -np.sum(pyz * np.log(pyz)) * dy * dz\n",
    "        hz = -np.sum(pz * np.log(pz)) * dz\n",
    "        cmi = hxz + hyz - h_joint - hz\n",
    "        return cmi\n",
    "    else:\n",
    "        dx = ds[0]\n",
    "        print('dx', dx)\n",
    "        dy = ds[1]\n",
    "        print('dy', dy)\n",
    "        px = p_joint.sum(axis=1) * dy\n",
    "        print(px)\n",
    "        py = p_joint.sum(axis=0) * dx\n",
    "        print(py)\n",
    "        hx = -np.sum(px * np.log(px)) * dx\n",
    "        hy = -np.sum(py * np.log(py)) * dy\n",
    "        mi = hx + hy - h_joint\n",
    "        print('XX', mi)\n",
    "        return mi\n",
    "\n",
    "\n",
    "def rbcv(x):\n",
    "    \"\"\"\n",
    "    :param x: array-like, (n_samples,)\n",
    "    :return: float, bandwidth\n",
    "    \"\"\"\n",
    "    bandwidth = np.array(mass.bcv(x))[0]\n",
    "    return bandwidth\n",
    "\n",
    "\n",
    "def drop_nan_columns(vectors):\n",
    "    \"\"\"\n",
    "    Keep only column positions that are not nan in all vectors.\n",
    "    :param vectors: list of numpy array, must have the same length (avoid [v1, ..., vn])\n",
    "    :return: list of numpy arrays,\n",
    "    \"\"\"\n",
    "    for v in vectors[1:]:\n",
    "        if len(v) != len(vectors[0]):\n",
    "            raise ValueError('Input arrays have different lengths.')\n",
    "            \n",
    "    not_nan_filter = [True] * len(vectors[0])\n",
    "    for v in vectors:\n",
    "        not_nan_filter &= ~np.isnan(v)\n",
    "    \n",
    "    only_not_nan = []\n",
    "    for i in range(len(vectors)):\n",
    "        only_not_nan.append(vectors[i][not_nan_filter])\n",
    "    return only_not_nan\n",
    "    \n",
    "    \n",
    "def add_jitter(vectors, inplace=False):\n",
    "    \"\"\"\n",
    "    Add jitter to vectors inplace.\n",
    "    :param vectors: numpy array,\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for i in range(len(vectors)):\n",
    "        vectors[i] += np.random.random_sample(vectors[i].size) * 1E-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([12.517, 14.706, np.nan, 14.12, np.nan, np.nan, np.nan, 12.255])\n",
    "y = np.array([0.98246356, 0.97525171, 0.77744759, 0.64084311, 0.4405853, 0.43827196, 0.12447757, 0.08116039])\n",
    "xx = np.random.random_sample(7)\n",
    "xx[3] = None\n",
    "yy = np.random.random_sample(7)\n",
    "yy[5]=None\n",
    "information_coefficient(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
