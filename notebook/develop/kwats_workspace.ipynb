{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as nplk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "import ccal\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'svg',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nfeatures = 10\n",
    "nelement = 10\n",
    "features = ccal.support.make_random_features(nfeatures, nelement)\n",
    "ref = ccal.support.make_random_features(1, nelement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, cophenet\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ccal.visualize import CMAP_CONTINUOUS, plot_nmf_result, plot_features_and_reference, FONT16_BOLD, FONT12_BOLD, FONT20_BOLD, BLACK\n",
    "from ccal.information import information_coefficient, cmi_diff, cmi_ratio\n",
    "from ccal.support import verbose_print, establish_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rank_features_against_reference(features, ref,\n",
    "                                    features_type='continuous', ref_type='continuous',\n",
    "                                    features_ascending=False, ref_ascending=False, ref_sort=True,\n",
    "                                    metric='ic', nsampling=3, confidence=0.95, nperm=3,\n",
    "                                    title=None, annotation_columns=('IC', 'Global', 'P-Value', 'CI', 'FDR (BH)'),\n",
    "                                    n_features=0.95, rowname_size=25,\n",
    "                                    output_prefix=None, figure_type='.png'):\n",
    "    \"\"\"\n",
    "    Compute features vs. `ref`.\n",
    "    :param features: pandas DataFrame (n_features, m_elements), must have indices and columns\n",
    "    :param ref: pandas Series (m_elements), must have name and columns, which must match 'features`'s\n",
    "    :param metric: str, {information_coef}\n",
    "    :param features_type: str, {continuous, categorical, binary}\n",
    "    :param ref_type: str, {continuous, categorical, binary}\n",
    "    :param features_ascending: bool, True if features score increase from top to bottom, False otherwise\n",
    "    :param ref_ascending: bool, True if ref values increase from left to right, False otherwise\n",
    "    :param ref_sort: bool, sort each ref or not\n",
    "    :param title: string for the title of heatmap\n",
    "    :param annotation_columns: list, annotation column names to include in the plot\n",
    "    :param n_features: int or float, number threshold if >= 1 and quantile threshold if < 1\n",
    "    :param rowname_size: int, the maximum length of a feature name label\n",
    "    :param output_prefix: str, file path prefix to save the result (.txt) and figure (`figure_type`)\n",
    "    :param figure_type: str, file type to save the output figure\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    verbose_print('Computing features vs. {} using {} metric ...'.format(ref.name, metric))\n",
    "\n",
    "    # Establish output file path\n",
    "    if output_prefix:\n",
    "        output_prefix = os.path.abspath(output_prefix)\n",
    "        establish_path(output_prefix)\n",
    "\n",
    "    # Use only the intersecting columns\n",
    "    # TODO: preserve order\n",
    "    col_intersection = set(features.columns) & set(ref.index)\n",
    "    verbose_print(\n",
    "        'Using {} intersecting columns from features and ref, which have {} and {} columns respectively ...'.format(\n",
    "            len(col_intersection), features.shape[1], ref.size))\n",
    "    features = features.ix[:, col_intersection]\n",
    "    ref = ref.ix[col_intersection]\n",
    "\n",
    "    # Sort ref and use its sorted indices to sort features indices\n",
    "    if ref_sort:\n",
    "        ref = ref.sort_values(ascending=ref_ascending)\n",
    "        features = features.reindex_axis(ref.index, axis=1)\n",
    "\n",
    "    # Compute scores, join them in features, and rank features based on scores\n",
    "    scores = compute_against_reference(features, ref, metric=metric, nsampling=nsampling, confidence=confidence, nperm=nperm)\n",
    "    # TODO: sort by features_ascending\n",
    "    features = features.reindex(scores.index)\n",
    "\n",
    "    # Make annotation\n",
    "    annotations = pd.DataFrame()\n",
    "    annotations['IC'] = ['{0:.2f}'.format(x) for x in scores.ix[:, 'ic']]\n",
    "    annotations['P'] = ['{0:.2f}'.format(x) for x in scores.ix[:, 'Global P-Value']]\n",
    "    annotations['CI'] = scores.ix[:, '{} CI'.format(confidence)].tolist()\n",
    "    \n",
    "    #     if output_prefix:\n",
    "    #         filename = output_prefix + '.txt'\n",
    "    #         features.to_csv(filename, sep='\\t')\n",
    "    #         verbose_print('Saved the result as {}.'.format(filename))\n",
    "\n",
    "    \n",
    "    # Plot features panel\n",
    "    verbose_print('Plotting top {} features vs. ref ...'.format(n_features))\n",
    "    if n_features < 1:\n",
    "        indices_to_plot = features.iloc[:, -1] >= features.iloc[:, -1].quantile(n_features)\n",
    "        indices_to_plot |= features.iloc[:, -1] <= features.iloc[:, -1].quantile(1 - n_features)\n",
    "    else:\n",
    "        indices_to_plot = features.index[:n_features].tolist() + features.index[-n_features:].tolist()\n",
    "    plot_features_and_reference(features, ref, annotations,\n",
    "                                features_type=features_type, ref_type=ref_type,\n",
    "                                title=title, rowname_size=rowname_size,\n",
    "                                filename_prefix=output_prefix, figure_type=figure_type)\n",
    "\n",
    "\n",
    "def compute_against_reference(features, ref, metric='ic', nsampling=3, confidence=0.95, nperm=3):\n",
    "    \"\"\"\n",
    "    Compute scores[i] = `features`[i] vs. `ref` with computation using `metric`.\n",
    "    :param features: pandas DataFrame (n_features, m_elements), must have indices and columns\n",
    "    :param ref: pandas Series (m_elements), must have indices, which must match 'features`'s columns\n",
    "    :param metric: str, {information}\n",
    "    :return: pandas DataFrame (n_features, 1),\n",
    "    \"\"\"\n",
    "    # Compute score[i] = <features>[i] vs. <ref>\n",
    "    if metric is 'ic':\n",
    "        function = information_coefficient\n",
    "    elif metric is 'information_cmi_diff':\n",
    "        function = cmi_diff\n",
    "    elif metric is 'information_cmi_ratio':\n",
    "        function = cmi_ratio\n",
    "    else:\n",
    "        raise ValueError('Unknown metric {}.'.format(metric))\n",
    "\n",
    "    # Score\n",
    "    scores = pd.DataFrame([function(row[1], ref) for row in features.iterrows()],\n",
    "                          index=features.index, columns=[metric])\n",
    "\n",
    "    print('Bootstrapping to get {} confidence interval ...'.format(confidence))\n",
    "    confidence_intervals = pd.DataFrame(index=features.index,\n",
    "                                        columns=['{} CI'.format(confidence)])\n",
    "    # Random sample elements\n",
    "    nsample = math.ceil(0.632 * features.shape[0])\n",
    "    sampled_scores = np.empty((features.shape[0], nsampling))\n",
    "    for i in range(nsampling):\n",
    "        sample_indices = np.random.choice(features.columns.tolist(), int(nsample)).tolist()\n",
    "        sampled_features = features.ix[:, sample_indices]\n",
    "        sampled_ref = ref.ix[sample_indices]\n",
    "        # Compute sample score\n",
    "        for j, (idx, s) in enumerate(sampled_features.iterrows()):\n",
    "            sampled_scores[j, i] = function(s, sampled_ref)\n",
    "    # Get confidence interval\n",
    "    z_critical = stats.norm.ppf(q=confidence)\n",
    "    for i, f in enumerate(sampled_scores):\n",
    "        mean = f.mean()\n",
    "        stdev = f.std()\n",
    "        moe = z_critical * (stdev / math.sqrt(f.size))\n",
    "        confidence_intervals.iloc[i] = '<{0:.2f}, {0:.2f}>'.format(mean - moe, mean + moe)\n",
    "\n",
    "    print('Performing permutation test with {} permutations ...'.format(nperm))\n",
    "    permutation_pvals_and_fdrs = pd.DataFrame(index=features.index,\n",
    "                                              columns=['Local P-Value', 'Global P-Value', 'FDR (BH)'])\n",
    "    permutation_scores = np.empty((features.shape[0], nperm))\n",
    "    # Permute ref and compute score against it\n",
    "    shuffled_ref = np.array(ref)\n",
    "    for i in range(nperm):\n",
    "        np.random.shuffle(shuffled_ref)\n",
    "        for j, (idx, s) in enumerate(features.iterrows()):\n",
    "            permutation_scores[j, i] = information_coefficient(s, shuffled_ref)\n",
    "    # Compute permutation p-value\n",
    "    all_permutation_scores = permutation_scores.flatten()\n",
    "    for i, (idx, f) in enumerate(scores.iterrows()):\n",
    "        # Local P-Value\n",
    "        local_pval = float(sum(permutation_scores[i, :] > float(f)) / nperm)\n",
    "        if not local_pval:\n",
    "            local_pval = float(1 / nperm)\n",
    "        permutation_pvals_and_fdrs.ix[idx, 'Local P-Value'] = local_pval\n",
    "\n",
    "        # Global P-Value\n",
    "        global_pval = float(sum(all_permutation_scores > float(f)) / (nperm * features.shape[0]))\n",
    "        if not global_pval:\n",
    "            global_pval = float(1 / (nperm * features.shape[0]))\n",
    "        permutation_pvals_and_fdrs.ix[idx, 'Global P-Value'] = global_pval\n",
    "    # Compute permutation FDR\n",
    "    permutation_pvals_and_fdrs.ix[:, 'FDR (BH)'] = multipletests(permutation_pvals_and_fdrs.ix[:, 'Global P-Value'],\n",
    "                                                                 method='fdr_bh')[1]\n",
    "    return pd.concat([scores, confidence_intervals, permutation_pvals_and_fdrs], axis=1).sort_values('ic')\n",
    "\n",
    "\n",
    "def plot_features_and_reference(features, ref, annotations, features_type='continuous', ref_type='continuous',\n",
    "                                title=None, rowname_size=25, filename_prefix=None, figure_type='.png'):\n",
    "    \"\"\"\n",
    "    Plot a heatmap panel.\n",
    "    :param features: pandas DataFrame (n_features, m_elements), must have indices and columns\n",
    "    :param ref: pandas Series (m_elements), must have indices, which must match 'features`'s columns\n",
    "    :param annotations:  pandas DataFrame (n_features, n_annotations), must have indices, which must match 'features`'s\n",
    "    :param features_type: str, {continuous, categorical, binary}\n",
    "    :param ref_type: str, {continuous, categorical, binary}\n",
    "    :param title: str, figure title\n",
    "    :param rowname_size: int, the maximum length of a feature name label\n",
    "    :param filename_prefix: str, file path prefix to save the figure\n",
    "    :param figure_type: str, file type to save the figure\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    features_nrow, features_ncol = features.shape\n",
    "\n",
    "    # Set figure size\n",
    "    if features_ncol < 10:\n",
    "        fig_width = 10 / 6\n",
    "    elif features_ncol < 35:\n",
    "        fig_width = features_ncol / 6\n",
    "    else:\n",
    "        fig_width = 35 / 6\n",
    "\n",
    "    if features_nrow < 3:\n",
    "        fig_height = 4 / 3\n",
    "    else:\n",
    "        fig_height = features_nrow / 3\n",
    "\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height), dpi=900)\n",
    "    text_margin = 1\n",
    "\n",
    "    # Set heatmap parameters for ref\n",
    "    if ref_type is 'continuous':\n",
    "        ref_cmap = CMAP_CONTINUOUS\n",
    "        ref_min, ref_max = -2.5, 2.5\n",
    "    elif ref_type is 'categorical':\n",
    "        ref_cmap = CMAP_CATEGORICAL\n",
    "        ref_min, ref_max = 0, np.unique(ref.values).size\n",
    "    elif ref_type is 'binary':\n",
    "        ref_cmap = CMAP_BINARY\n",
    "        ref_min, ref_max = 0, 1\n",
    "    else:\n",
    "        raise ValueError('Unknown ref_type {}.'.format(ref_type))\n",
    "\n",
    "    # Set heatmap parameters for features\n",
    "    if features_type is 'continuous':\n",
    "        features_cmap = CMAP_CONTINUOUS\n",
    "        features_min, features_max = -2.5, 2.5\n",
    "    elif features_type is 'categorical':\n",
    "        features_cmap = CMAP_CATEGORICAL\n",
    "        features_min, features_max = 0, np.unique(features.values).size\n",
    "    elif features_type is 'binary':\n",
    "        features_cmap = CMAP_BINARY\n",
    "        features_min, features_max = -0.025, 1\n",
    "    else:\n",
    "        raise ValueError('Unknown features_type {}.'.format(features_type))\n",
    "\n",
    "    # Normalize\n",
    "    if features_type is 'continuous':\n",
    "        verbose_print('Normalizing continuous features ...')\n",
    "        for i, (idx, s) in enumerate(features.iterrows()):\n",
    "            mean = s.mean()\n",
    "            std = s.std()\n",
    "            for j, v in enumerate(s):\n",
    "                features.iloc[i, j] = (v - mean) / std\n",
    "    if ref_type is 'continuous':\n",
    "        verbose_print('Normalizing continuous ref ...')\n",
    "        ref = (ref - ref.mean()) / ref.std()\n",
    "\n",
    "    # Plot ref\n",
    "    ref_ax = plt.subplot2grid((features_nrow, 1), (0, 0))\n",
    "    ref_ax.text(features_ncol / 2, 4 * text_margin, title,\n",
    "                horizontalalignment='center', verticalalignment='bottom', **FONT16_BOLD)\n",
    "    sns.heatmap(pd.DataFrame(ref).T, vmin=ref_min, vmax=ref_max, robust=True,\n",
    "                cmap=ref_cmap, linecolor=BLACK, fmt=None, xticklabels=False, yticklabels=False, cbar=False)\n",
    "    # Add ref texts\n",
    "    ref_ax.text(-text_margin, 0.5, ref.name,\n",
    "                horizontalalignment='right', verticalalignment='center', **FONT12_BOLD)\n",
    "    for j, a in enumerate(annotations.columns):\n",
    "        ref_ax.text(features_ncol + text_margin * (4 * j + text_margin), 0.5, a,\n",
    "                         horizontalalignment='left', verticalalignment='center', **FONT12_BOLD)\n",
    "\n",
    "    # Add binary or categorical ref labels\n",
    "    if ref_type in ('binary', 'categorical'):\n",
    "        # Find boundaries\n",
    "        boundaries = [0]\n",
    "        prev_v = ref.iloc[0]\n",
    "        for i, v in enumerate(ref.iloc[1:]):\n",
    "            if prev_v != v:\n",
    "                boundaries.append(i + 1)\n",
    "            prev_v = v\n",
    "        boundaries.append(features_ncol)\n",
    "        # Calculate label's horizontal positions\n",
    "        label_horizontal_positions = []\n",
    "        prev_b = 0\n",
    "        for b in boundaries[1:]:\n",
    "            label_horizontal_positions.append(b - (b - prev_b) / 2)\n",
    "            prev_b = b\n",
    "        # TODO: get_unique_in_order\n",
    "        unique_ref_labels = np.unique(ref.values)[::-1]\n",
    "        # Add labels\n",
    "        for i, pos in enumerate(label_horizontal_positions):\n",
    "            # TODO: verticalalignment should be default so remove this\n",
    "            ref_ax.text(pos, 1, unique_ref_labels[i],\n",
    "                        horizontalalignment='center', verticalalignment='bottom', **FONT12_BOLD)\n",
    "\n",
    "    # Plot features\n",
    "    features_ax = plt.subplot2grid((features_nrow, 1), (0, 1), rowspan=features_nrow)\n",
    "    sns.heatmap(features, vmin=features_min, vmax=features_max, robust=True,\n",
    "                cmap=features_cmap, linecolor=BLACK, fmt=None, xticklabels=False, yticklabels=False, cbar=False)\n",
    "\n",
    "    for i, idx in enumerate(features.index):\n",
    "        y = features_nrow - i - 0.5\n",
    "        features_ax.text(-text_margin, y, idx[:rowname_size],\n",
    "                         horizontalalignment='right', verticalalignment='center', **FONT12_BOLD)\n",
    "        for j, a in enumerate(annotations.iloc[i, :]):\n",
    "            features_ax.text(features_ncol + text_margin * (4 * j + text_margin), y, a,\n",
    "                             horizontalalignment='left', verticalalignment='center', **FONT12_BOLD)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show(fig)\n",
    "\n",
    "    if filename_prefix:\n",
    "        filename = filename_prefix + figure_type\n",
    "        fig.savefig(filename)\n",
    "        verbose_print('Saved the figure as {}.'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank_features_against_reference(features, ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
